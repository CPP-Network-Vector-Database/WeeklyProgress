{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9925645,"sourceType":"datasetVersion","datasetId":6098258}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install torch transformers faiss-cpu pandas","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T02:35:27.015895Z","iopub.execute_input":"2025-03-09T02:35:27.016227Z","iopub.status.idle":"2025-03-09T02:35:33.092790Z","shell.execute_reply.started":"2025-03-09T02:35:27.016199Z","shell.execute_reply":"2025-03-09T02:35:33.091733Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nCollecting faiss-cpu\n  Downloading faiss_cpu-1.10.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading faiss_cpu-1.10.0-cp310-cp310-manylinux_2_28_x86_64.whl (30.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-cpu\nSuccessfully installed faiss-cpu-1.10.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"pip install sentence-transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T02:35:33.094353Z","iopub.execute_input":"2025-03-09T02:35:33.094677Z","iopub.status.idle":"2025-03-09T02:35:36.441266Z","shell.execute_reply.started":"2025-03-09T02:35:33.094651Z","shell.execute_reply":"2025-03-09T02:35:36.440214Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.47.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.29.0)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nimport faiss\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T02:35:36.443191Z","iopub.execute_input":"2025-03-09T02:35:36.443464Z","iopub.status.idle":"2025-03-09T02:35:58.581204Z","shell.execute_reply.started":"2025-03-09T02:35:36.443438Z","shell.execute_reply":"2025-03-09T02:35:58.580491Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# pretrained Sentence-BERT model\nmodel = SentenceTransformer(\"paraphrase-MiniLM-L12-v2\")\n\ncsv_path = \"/kaggle/input/pcap-2019-dira-125910/dirA.125910-packets.csv\"\ndf = pd.read_csv(csv_path, header=None, names=[\"timestamp\", \"src_ip\", \"dst_ip\", \"protocol\", \"size\"])\n\n# packet data to text format for BERT processing\ndf[\"packet_text\"] = df[\"src_ip\"] + \" \" + df[\"dst_ip\"] + \" \" + df[\"protocol\"] + \" \" + df[\"size\"].astype(str)\n\n# Generate embeddings\nembeddings = model.encode(df[\"packet_text\"].tolist(), convert_to_numpy=True)\n\n# Normalize embeddings (cuz FAISS works better with normalized vectors)\nembeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n\n# Creating FAISS index\ndimension = embeddings.shape[1] # 384 is embedding size for MiniLM\nindex = faiss.IndexFlatL2(dimension)\nindex.add(embeddings)  # all embeddings stored in FAISS\n\nprint(f\"FAISS index contains {index.ntotal} embeddings.\")\n\n# Saving FAISS index\nfaiss.write_index(index, \"packet_embeddings.index\")\n\n# original packet data with embeddings\ndf.to_csv(\"packet_metadata.csv\", index=False)\n\nprint(\"FAISS index and metadata saved.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T02:35:58.582019Z","iopub.execute_input":"2025-03-09T02:35:58.582483Z","iopub.status.idle":"2025-03-09T02:48:04.903954Z","shell.execute_reply.started":"2025-03-09T02:35:58.582460Z","shell.execute_reply":"2025-03-09T02:48:04.903184Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f31bc87fa5d8400dab75bed1d2e9c4f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b5d056f569e4c6fa63f9bbc3cf6d8e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/3.52k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ef0036e1c8941d2ac2cc65383bdaf70"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e3d758dfab34e55b5f6bc3fce16f0b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/631 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"275084aab1514997a6503cc557fa7004"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8291f6e9b8141c29a6dc4cac670ed44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bce3feba6c64b96b2c0331a40cdc189"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23c13723888e4f74a7b48670ac44c3e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d3c154392194c4baa294f8c63e49fff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6e3919c46ee476bbbecac9c7a9eaa36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4f7743eaccf44e2af11154aa84cfa2a"}},"metadata":{}},{"name":"stderr","text":"<ipython-input-6-90dac8e1cb9c>:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n  df = pd.read_csv(csv_path, header=None, names=[\"timestamp\", \"src_ip\", \"dst_ip\", \"protocol\", \"size\"])\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/51663 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7d31a28b5294d87b4e9226d9c6e3565"}},"metadata":{}},{"name":"stdout","text":"FAISS index contains 1653188 embeddings.\nFAISS index and metadata saved.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Performance logging","metadata":{}},{"cell_type":"code","source":"import time\nimport faiss\nimport numpy as np\nimport pandas as pd\nimport psutil\nfrom sentence_transformers import SentenceTransformer\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T02:51:32.095244Z","iopub.execute_input":"2025-03-09T02:51:32.095575Z","iopub.status.idle":"2025-03-09T02:51:32.099739Z","shell.execute_reply.started":"2025-03-09T02:51:32.095552Z","shell.execute_reply":"2025-03-09T02:51:32.098900Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def measure(pid, func, *args, **kwargs):\n    process = psutil.Process(pid)\n    \n    # Initial resource usage\n    start_cpu = process.cpu_percent(interval=None)\n    start_mem = process.memory_info().rss / (1024 ** 2)  # Convert to MB\n    start_time = time.time()\n    \n    # Run function\n    result = func(*args, **kwargs)\n    \n    # Final resource usage\n    end_cpu = process.cpu_percent(interval=None)\n    end_mem = process.memory_info().rss / (1024 ** 2)  # Convert to MB\n    end_time = time.time()\n    \n    # Compute diff\n    cpu_usage = end_cpu - start_cpu\n    mem_usage = end_mem - start_mem\n    execution_time = end_time - start_time\n\n    print(f\"Function: {func.__name__} | Time: {execution_time:.4f}s | CPU: {cpu_usage:.2f}% | Mem: {mem_usage:.2f}MB\")\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T02:51:32.879871Z","iopub.execute_input":"2025-03-09T02:51:32.880154Z","iopub.status.idle":"2025-03-09T02:51:32.885170Z","shell.execute_reply.started":"2025-03-09T02:51:32.880132Z","shell.execute_reply":"2025-03-09T02:51:32.884266Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"### 1. Queryng a new packet\nSteps: \n1. Convert the query packet into text format.\n2. Generate its BERT embedding.\n3. Normalize the embedding (since FAISS works best with normalized vectors).\n4. Search the FAISS index for the k-nearest neighbors.\n5. Return the top-k results with their distances (lower = more similar).","metadata":{}},{"cell_type":"code","source":"def query_faiss(index, query_embedding, k=5):\n    distances, indices = index.search(query_embedding, k)\n    return indices\n\n# Query FAISS index with a random packet\nquery_text = [\"192.168.1.1 192.168.1.2 TCP 100\"]\nquery_embedding = model.encode(query_text, convert_to_numpy=True)\nquery_embedding = query_embedding / np.linalg.norm(query_embedding, axis=1, keepdims=True)\n\npid = os.getpid()\nquery_result = measure(pid, query_faiss, index, query_embedding, 5)\nprint(f\"Top 5 similar packet indices: {query_result}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T02:51:35.353906Z","iopub.execute_input":"2025-03-09T02:51:35.354222Z","iopub.status.idle":"2025-03-09T02:51:35.626641Z","shell.execute_reply.started":"2025-03-09T02:51:35.354197Z","shell.execute_reply":"2025-03-09T02:51:35.625645Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a1bde610744456ab90cd65bf80e7305"}},"metadata":{}},{"name":"stdout","text":"Function: query_faiss | Time: 0.2331s | CPU: 98.70% | Mem: 0.25MB\nTop 5 similar packet indices: [[ 767365  325967 1001693 1234941 1645756]]\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"### 2. Large Insertions\nSteps: \n1. Convert 50+ new packets into embeddings.\n2. Normalize them.\n3. Add to the FAISS index.","metadata":{}},{"cell_type":"code","source":"def insert_data(index, new_embeddings):\n    index.add(new_embeddings)\n    print(f\"Inserted {len(new_embeddings)} new vectors into FAISS index.\")\n\n# Simulate inserting 50 new packets at random\nnew_packet_texts = [f\"192.168.1.{i} 192.168.1.{i+1} TCP {i*10}\" for i in range(50)]\nnew_embeddings = model.encode(new_packet_texts, convert_to_numpy=True)\nnew_embeddings = new_embeddings / np.linalg.norm(new_embeddings, axis=1, keepdims=True)\n\npid = os.getpid()\nmeasure(pid, insert_data, index, new_embeddings)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T02:51:38.371346Z","iopub.execute_input":"2025-03-09T02:51:38.371624Z","iopub.status.idle":"2025-03-09T02:51:40.825113Z","shell.execute_reply.started":"2025-03-09T02:51:38.371602Z","shell.execute_reply":"2025-03-09T02:51:40.824363Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58c28fc8964c43ebb559ba6973992fdb"}},"metadata":{}},{"name":"stdout","text":"Inserted 50 new vectors into FAISS index.\nFunction: insert_data | Time: 2.3957s | CPU: 99.80% | Mem: 0.06MB\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"### 3. Large Deletions\n**Problem!!!**\n**FAISS does not support direct deletion of individual embeddings.**\n\nWorkaround:\n1. Remove entries from the metadata CSV.\n2. Rebuild the FAISS index without the deleted embeddings.","metadata":{}},{"cell_type":"code","source":"def delete_from_faiss(index, delete_indices, embeddings):\n    #delete by rebuilding the index with the remaining embeddings.\n    if not isinstance(delete_indices, np.ndarray):\n        delete_indices = np.array(delete_indices)\n\n    # Ensure delete_indices are valid\n    delete_indices = delete_indices[delete_indices < embeddings.shape[0]]\n\n    # Create a mask for filtering\n    mask = np.ones(embeddings.shape[0], dtype=bool)\n    mask[delete_indices] = False\n\n    # Select embeddings that are not deleted\n    new_embeddings = embeddings[mask]\n\n    # Rebuild the FAISS index with remaining embeddings\n    new_index = faiss.IndexFlatL2(new_embeddings.shape[1])\n    new_index.add(new_embeddings)\n\n    return new_index, new_embeddings  # Return updated index and embeddings\n\ndelete_indices = np.random.choice(embeddings.shape[0], 50, replace=False)\n\npid = os.getpid()\nindex, embeddings = measure(pid, delete_from_faiss, index, delete_indices, embeddings)\nprint(f\"Deleted {len(delete_indices)} embeddings from FAISS index.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T02:51:43.865179Z","iopub.execute_input":"2025-03-09T02:51:43.865468Z","iopub.status.idle":"2025-03-09T02:51:47.297551Z","shell.execute_reply.started":"2025-03-09T02:51:43.865446Z","shell.execute_reply":"2025-03-09T02:51:47.296645Z"}},"outputs":[{"name":"stdout","text":"Function: delete_from_faiss | Time: 3.1473s | CPU: 99.80% | Mem: 4843.23MB\nDeleted 50 embeddings from FAISS index.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"### 4. Large Updates\nSimilar to delete + insert.\n\nJust remove old embeddings from FAISS, recompute new ones, and reinsert.","metadata":{}},{"cell_type":"code","source":"def update_faiss(index, update_indices, new_packet_texts, embeddings):\n    # update by deleting specific indices and inserting new embeddings\n    index, embeddings = delete_from_faiss(index, update_indices, embeddings)\n\n    # Compute new embeddings\n    new_embeddings = model.encode(new_packet_texts, convert_to_numpy=True)\n    new_embeddings = new_embeddings / np.linalg.norm(new_embeddings, axis=1, keepdims=True)\n\n    # Add new embeddings to FAISS\n    index.add(new_embeddings)\n\n    # Append new embeddings to the stored array\n    embeddings = np.vstack([embeddings, new_embeddings])\n\n    return index, embeddings  # Return updated index and embeddings\n\n# Simulate updating 50 packets\nupdate_indices = np.random.choice(embeddings.shape[0], 50, replace=False)\nnew_packet_texts = [f\"10.0.0.{i} 10.0.0.{i+1} UDP {i*5}\" for i in range(50)]\n\npid = os.getpid()\nindex, embeddings = measure(pid, update_faiss, index, update_indices, new_packet_texts, embeddings)\nprint(f\"Updated {len(update_indices)} embeddings in FAISS index.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T02:51:52.643867Z","iopub.execute_input":"2025-03-09T02:51:52.644186Z","iopub.status.idle":"2025-03-09T02:51:59.406303Z","shell.execute_reply.started":"2025-03-09T02:51:52.644160Z","shell.execute_reply":"2025-03-09T02:51:59.405381Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b305fea0624425c8ddc01e2b3ef74fa"}},"metadata":{}},{"name":"stdout","text":"Function: update_faiss | Time: 6.4721s | CPU: 100.10% | Mem: 4843.18MB\nUpdated 50 embeddings in FAISS index.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}